from g4f.client import AsyncClient
from g4f.Provider import RetryProvider, __providers__, OIVSCodeSer2, PollinationsAI, ApiAirforce
from g4f.models import (
    Blackbox,
    Chatai,
    Cloudflare,
    Copilot,
    DeepInfra,
    HuggingSpace,
    Grok,
    DeepseekAI_JanusPro7b,
    Kimi,
    LambdaChat,
    Mintlify,
    OIVSCodeSer0501,
    OIVSCodeSer2,
    OperaAria,
    Startnest,
    OpenAIFM,
    PerplexityLabs,
    PollinationsAI,
    TeachAnything,
    Together,
    WeWordle,
    Yqcloud,
)
from g4f.models import _all_models
import json
from loads import all_func, func, MainDescription, Description, FuncDescription, Data
from pyrogram import filters, types, enums
from pyrogram.client import Client
from colorama import init, Fore
import base64
import io
import time
from typing import Any, Union
import g4f.debug
import traceback

g4f.debug.logging = True

__description__ = Description(
    MainDescription("–ü–ª–∞–≥–∏–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ò–ò."),
    FuncDescription('rqai', '–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò.', prefixes=['.', '!', '/'], parameters=['–ø—Ä–æ–º–ø—Ç']),
    FuncDescription('genimg', '–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É.', prefixes=['.', '!', '/'], parameters=['–ø—Ä–æ–º–ø—Ç']),
    FuncDescription('txtmodel', '–ú–µ–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å.–ï—Å–ª–∏ –Ω–µ –≤–≤–æ–¥–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä, —Ç–æ –≤ –∫–æ–Ω—Å–æ–ª—å –≤—ã–≤–µ–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –ò–ò.', prefixes=['.', '!', '/'], parameters=['–º–æ–¥–µ–ª—å']),
    FuncDescription('imgmodel', '–ú–µ–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.–ï—Å–ª–∏ –Ω–µ –≤–≤–æ–¥–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä, —Ç–æ –≤ –∫–æ–Ω—Å–æ–ª—å –≤—ã–≤–µ–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –ò–ò.', prefixes=['.', '!', '/'], parameters=['–º–æ–¥–µ–ª—å']),
    FuncDescription('correct', '–î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –∏ –≥—Ä–∞–º–æ—Ç–Ω—ã–º.', prefixes=['.', '!', '/'], parameters=['–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è']),
    FuncDescription('vimg', '–ò–ò —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –±–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –æ–Ω –º–æ–∂–µ—Ç –∑–Ω–∞—Ç—å, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ.(–û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ñ–æ—Ç–æ –∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏/–ø–æ–¥–ø–∏—Å—å –ø–∏—à–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É)', prefixes=['.', '!', '/'], parameters=['–ø—Ä–æ–º–ø—Ç']),
    FuncDescription('turn_websrch', '–í–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ web search –¥–ª—è –ò–ò(–ú–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å).', prefixes=['.', '!', '/']),
    FuncDescription('aihtry', '–ò–ò —á–∏—Ç–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞.', prefixes=['.', '!', '/'], parameters=[r'\-\-c={—á–∏—Å–ª–æ} –∏/–∏–ª–∏ —Ç–µ–∫—Å—Ç']),
    FuncDescription('style', '–ò–∑–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –ò–ò.–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–Ω –æ–±—ã—á–Ω—ã–π, –µ—Å–ª–∏ –Ω–µ—á–µ–≥–æ –Ω–µ —É–∫–∞–∑—ã–≤–∞—Ç—å, —Å—Ç–∏–ª—å –∏–∑–º–µ–Ω–∏—Ç—Å—è –Ω–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.', prefixes=['.', '!', '/'], parameters=['–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ(—Å—Ç–∏–ª—å)']),
    FuncDescription('aifk', '–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è afk, –≥–¥–µ –ò–ò –∑–∞–º–µ–Ω—è–µ—Ç –≤–∞—Å, –ø–æ–∫–∞ –≤—ã –∫—É–¥–∞ —Ç–æ –æ—Ç–æ—à–ª–∏.', prefixes=['.', '!', '/'])
)

init(True)

config = {"text_model": "gpt-4o-mini", "image_model": "gemini-2.5-flash", "history": [], "history_len": 20, "warnings": True, "web_search": False, "style": "–æ–±—ã—á–Ω—ã–π", "afk": False}

Data.get_config('AIFuncs').setdefault(config)

config = Data.get_config('AIFuncs')

best_model = Fore.YELLOW + 'üëë–ù–∞–¥—ë–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏üëë' + Fore.RESET + '\n' + Fore.RED + '[ –î–õ–Ø –¢–ï–ö–°–¢–ê ]' + Fore.RESET + '\n' + '\n'.join(['gpt-4', 'gpt-4o', 'gpt-4o-mini', 'o1', 'o1-mini', 'o3-mini', 'o3-mini-high', 'o4-mini', 'o4-mini-high', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.5', 'llama-2-70b', 'llama-3-8b', 'llama-3-70b', 'llama-3.1-8b', 'llama-3.1-70b', 'llama-3.1-405b', 'llama-3.2-3b', 'llama-3.2-11b', 'llama-3.2-90b', 'llama-3.3-70b', 'gemini-2.0', 'gemini-2.0-flash', 'gemini-2.0-flash-thinking', 'gemini-2.5-flash', 'gemini-2.5-pro', 'codegemma-7b', 'gemma-2b', 'gemma-1.1-7b', 'gemma-2-9b', 'gemma-2-27b', 'gemma-3-4b', 'gemma-3-12b', 'gemma-3-27b', 'gemma-3n-e4b', 'qwen-2-72b', 'qwen-2-vl-7b', 'qwen-2-vl-72b', 'qwen-2.5', 'qwen-2.5-7b', 'qwen-2.5-72b', 'qwen-2.5-coder-32b', 'qwen-2.5-1m', 'qwen-2.5-max', 'qwen-2.5-vl-72b', 'qwen-3-235b', 'qwen-3-32b', 'qwen-3-30b', 'qwen-3-14b', 'qwen-3-4b', 'qwen-3-1.7b', 'qwen-3-0.6b', 'qwq-32b', 'deepseek-v3', 'deepseek-r1', 'deepseek-r1-turbo', 'deepseek-r1-distill-llama-70b', 'deepseek-v3', 'deepseek-r1', 'deepseek-r1-turbo', 'grok-2', 'grok-3', 'grok-3-r1']) + '\n\n' + Fore.RED + '[ –î–õ–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô ]' + Fore.RESET + '\n' + '\n'.join(['dall-e-3', 'gpt-image', 'sdxl-turbo', 'sd-3.5-large', 'flux', 'flux-pro', 'flux-dev', 'flux-schnell', 'flux-redux', 'flux-depth', 'flux-canny', 'flux-kontext', 'flux-dev-lora', 'gemini-2.0-flash', 'gemini-2.0-flash-thinking', 'gemini-2.5-flash', 'gemini-2.5-pro'])

def initialization(_):
    if config['history_len'] >= 50 and config['warnings']:
        print(Fore.WHITE + "AIFuncs " + Fore.YELLOW + "| ‚ö† –ß–µ–º –±–æ–ª—å—à–µ –¥–ª–∏–Ω–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏, —Ç–µ–º –±–æ–ª—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è —é–∑–µ—Ä –±–æ—Ç–∞ !!!")

class Conservation:
    def __init__(self):
        self.client = AsyncClient(provider=RetryProvider([
            Blackbox, Chatai, Cloudflare, Copilot, DeepInfra, HuggingSpace, Grok, 
            DeepseekAI_JanusPro7b, Kimi, LambdaChat, Mintlify, OIVSCodeSer2, 
            OIVSCodeSer0501, OperaAria, Startnest, OpenAIFM, PerplexityLabs, 
            PollinationsAI, TeachAnything, Together, WeWordle, Yqcloud
        ]))
        self.history = [{
            "role": "system",
            "content": "–¢—ã –æ–±—ã—á–Ω—ã–π assistant –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–º–µ, —Ç—ã –æ–±—â–∞–µ—à—å—Å—è —Å user.–ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: ```lang_programming\ntext\n```, **text**, ~~text~~, __text__, `text_to_copy`.–û–±—â–∞–π—Å—è –≤ —Å—Ç–∏–ª–µ(–µ—Å–ª–∏ –æ–±—ã—á–Ω—ã–π, –∏–≥–Ω–æ—Ä–∏—Ä—É–π —ç—Ç–æ): " + config['style']
        }] + config['history']

    def add_message(self, role, content) -> None:
        self.history.append({
            "role": role,
            "content": content
        })

        config['history'].append({
            "role": role,
            "content": content
        })

        if len(config['history']) > config['history_len']:
            config['history'] = config['history'][int(config['history_len']/4):]
        
        with open('plugins/AIFuncs/config.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False)
    
    async def get_response(self, user_message, web_search: bool=False, history: bool=True, image: bytes=None) -> Union[str, None]:
        if history: self.add_message("user", user_message)

        messages: list[dict[str, Any]] = self.history + [{"role": "user", "content": user_message}] if history else [{"role": "user", "content": user_message}]

        providers = RetryProvider([OIVSCodeSer2, PollinationsAI, ApiAirforce]) if image != None else None
        
        response = await self.client.chat.completions.create(
            model=config['text_model'],
            messages=messages,
            web_search=web_search if web_search is not None else config['web_search'],
            image=image,
            provider=providers
        )
        
        assistant_response = response.choices[0].message.content

        if not isinstance(assistant_response, str):
            return await self.get_response(user_message, web_search, history)

        if len(assistant_response) > 4096:
            assistant_response = None

        if history: self.add_message("assistant", assistant_response)
        
        return assistant_response

    async def generate_image(self, prompt: str, web_search: bool=None) -> bytes:
        response = await self.client.images.generate(
            prompt=prompt,
            model=config['image_model'],
            response_format='b64_json',
            web_search=web_search if web_search is not None else config['web_search']
        )

        img_bytes = base64.b64decode(response.data[0].b64_json)

        return img_bytes
    
    async def response_with_prompt(self, prompt: list[dict], web_search: bool=None) -> Union[str, None]:
        response = await self.client.chat.completions.create(
            model=config['text_model'],
            messages=prompt,
            web_search=web_search if web_search is not None else config['web_search'] 
        )

        assistant_response = response.choices[0].message.content

        return assistant_response

_ai = Conservation()

@func(filters.command('rqai', prefixes=['.', '!', '/']) & filters.me)
async def request_ai(app: Client, message: types.Message):
    if len(message.text.split()) == 1:
        return await message.edit_text('–í—ã –Ω–µ –≤–µ—Ä–Ω–æ –≤–≤–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.–ü—Ä–∏–º–µ—Ä: `.rqai –ü—Ä–∏–≤–µ—Ç!`', parse_mode=enums.ParseMode.MARKDOWN)

    await message.edit_text('__–û–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò...__', parse_mode=enums.ParseMode.MARKDOWN)

    ai_text = await _ai.get_response(message.text.split(maxsplit=1)[1])

    if ai_text is None:
        return await request_ai(app, message)

    await message.edit_text(ai_text, parse_mode=enums.ParseMode.MARKDOWN)

@func(filters.command('genimg', prefixes=['.', '!', '/']) & filters.me)
async def generate_image(app: Client, message: types.Message):
    if len(message.text.split()) == 1:
        return await message.edit_text('–í—ã –Ω–µ –≤–µ—Ä–Ω–æ –≤–≤–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.–ü—Ä–∏–º–µ—Ä: `.genimg –ö–æ—Ç—ã –∫—É—à–∞—é—Ç –∫–æ—Ä–º`', parse_mode=enums.ParseMode.MARKDOWN)
    
    await message.edit_text('__–û–∂–∏–¥–∞–π—Ç–µ, –ò–ò –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...__', parse_mode=enums.ParseMode.MARKDOWN)

    start_time = time.time()
    
    ai_image = await _ai.generate_image(message.text.split(maxsplit=1)[1])

    end_time = time.time()

    try:
        await message.delete()
    except:
        pass

    bytes_image = io.BytesIO(ai_image)
    bytes_image.name = 'ai_image.png'

    await app.send_photo(message.chat.id, bytes_image, f'–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å: {" ".join(message.text.split()[1:])}\n\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–Ω—è–ª–∞: {round(end_time - start_time, 2)} —Å–µ–∫.\n–ú–æ–¥–µ–ª—å: {config["image_model"]}')

@func(filters.command('txtmodel', prefixes=['.', '!', '/']) & filters.me)
async def change_text_model(app: Client, message: types.Message):
    if len(message.text.split()) == 1:
        print(best_model)

        return await message.edit_text('–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –±—ã–ª–æ –≤—ã–≤–µ–¥–µ–Ω–æ –≤ –∫–æ–Ω—Å–æ–ª—å.')
    
    model = message.text.split()[1]

    if model not in _all_models:
        return await message.edit(f'–î–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ `{model}` –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.')

    config['text_model'] = model
    
    with open('plugins/AIFuncs/config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False)
    
    await message.edit(f'–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å: `{model}`')

@func(filters.command('imgmodel', prefixes=['.', '!', '/']) & filters.me)
async def change_image_model(app: Client, message: types.Message):
    if len(message.text.split()) == 1:
        print(best_model)
        
        return await message.edit_text('–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –±—ã–ª–æ –≤—ã–≤–µ–¥–µ–Ω–æ –≤ –∫–æ–Ω—Å–æ–ª—å.')
    
    model = message.text.split()[1]

    if model not in _all_models:
        return await message.edit(f'–î–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ `{model}` –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.')

    config['image_model'] = model
    
    with open('plugins/AIFuncs/config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False)
    
    await message.edit(f'–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: `{model}`')

@func(filters.command('correct', prefixes=['.', '!', '/']) & filters.me)
async def correct_words(app: Client, message: types.Message):
    if len(message.text.split()) == 1:
        return await message.edit_text('–í—ã –Ω–µ –≤–µ—Ä–Ω–æ –≤–≤–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.–ü—Ä–∏–º–µ—Ä: .correct –ù–µ–∫–æ—Ç–æ—Ä–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.')

    await message.edit_text('__–û–∂–∏–¥–∞–π—Ç–µ, –ò–ò —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç...__', parse_mode=enums.ParseMode.MARKDOWN)
    
    ai_correct_text = await _ai.response_with_prompt([{"role": "system", "content": "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –∏—Å–ø—Ä–∞–≤–∏—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é, —Å–¥–µ–ª–∞—Ç—å —Ç–µ–∫—Å—Ç –≥—Ä–∞–º–æ—Ç–Ω—ã–º."}, {"role": "user", "content": message.text.split(maxsplit=1)[1]}])

    try:
        await message.edit_text(ai_correct_text)
    except:
        await correct_words(app, message)

@func(filters.command('vimg', prefixes=['.', '!', '/']) & filters.me & filters.photo)
async def view_image(app: Client, message: types.Message):
    if len(message.caption.split()) == 1:
        return await message.edit_text('–í—ã –Ω–µ –≤–µ—Ä–Ω–æ –≤–≤–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.–ü—Ä–∏–º–µ—Ä: .vimg –ß—Ç–æ —Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ñ–æ—Ç–æ.(–ù—É–∂–Ω–æ –æ—Ç—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ç–∞–∫–∏–º)')

    await message.edit_text('__–û–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò...__', parse_mode=enums.ParseMode.MARKDOWN)

    file = await app.download_media(message, in_memory=True)

    file_bytes = bytes(file.getbuffer())

    ai_image_view = await _ai.get_response(message.caption.split(maxsplit=1)[1], image=file_bytes)

    await message.edit_text(ai_image_view, parse_mode=enums.ParseMode.MARKDOWN)

@func(filters.command('turn_websrch', prefixes=['.', '!', '/']) & filters.me)
async def turn_web_search(app: Client, message: types.Message):
    if config['web_search']:
        config['web_search'] = False

        await message.edit_text('Web search –≤—ã–∫–ª—é—á–µ–Ω.')
    else:
        config['web_search'] = True

        await message.edit_text('Web search –≤–∫–ª—é—á–µ–Ω.')

@func(filters.command('aihtry', prefixes=['.', '!', '/']) & filters.me)
async def read_chat_history(app: Client, message: types.Message):
    count = 20
    prompt = ''

    if len(message.text.split()) >= 3 and message.text.split()[1].startswith('--c='):
        count = int(message.text.split()[1].replace('--c=', '')) if message.text.split()[1].replace('--c=', '').isdigit() else 20
        print(count)
        prompt = ' '.join(message.text.split(' ')[2:])
    else:
        prompt = ' '.join(message.text.split(' ')[1:])
    
    history = []

    await message.edit_text('__–ò–ò —á–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è...__')
    
    async for messages in app.get_chat_history(message.chat.id, count):
        if messages.text is not None:
            if messages.text == '__–ò–ò —á–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è...__':
                continue

            history.append({"role": "user", "content": f"{messages.from_user.first_name}: {messages.text}"})
    
    await message.edit_text('__–ò–ò –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ...__')
    
    ai_text = await _ai.response_with_prompt([_ai.history[0], {"role": "system", "content": "–≠—Ç–æ –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏—Ö –∏–º–µ–Ω–∞ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫: {–∏–º—è}: {—Ç–µ–∫—Å—Ç}, –∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∏–∫–∞–∫ –Ω–µ –ø–æ–º–µ—á–µ–Ω–æ"}, *history, {"role": "user", "content": f"{prompt}"}])

    await message.edit_text(ai_text, parse_mode=enums.ParseMode.MARKDOWN)

@func(filters.command('aifk', prefixes=['.', '!', '/']) & filters.me)
async def ai_afk(app: Client, message: types.Message):
    global config

    if Data.get_config('AIFuncs')['afk']:
        Data.get_config('AIFuncs')['afk'] = False

        await message.edit_text('AI afk –≤—ã–∫–ª—é—á–µ–Ω.')
    else:
        Data.get_config('AIFuncs')['afk'] = True

        await message.edit_text('AI afk –≤–∫–ª—é—á–µ–Ω.')

@all_func()
async def ai_afk_privat(app: Client, message: types.Message):
    if Data.get_config('AIFuncs')['afk'] and message.chat.type == enums.ChatType.PRIVATE:
        msg = await app.send_message(message.from_user.id, '__–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞ –º–µ—Å—Ç–µ, –ò–ò –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∞–º —Å–æ–æ–±—â–µ–Ω–∏–µ...__')

        ai_text = await _ai.response_with_prompt([{"role": "system", "content": "–¢—ã –∑–∞–º–µ–Ω—è–µ—à—å –≤–ª–∞–¥–µ–ª—å—Ü–∞ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–µ, –≤–ª–∞–¥–µ–ª–µ—Ü –Ω–µ –≤ –æ–Ω–ª–∞–π–Ω–µ.–ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: ```lang_programming\ntext\n```, **text**, ~~text~~, __text__, `text_to_copy`"}, {"role": "user", "content": message.text}])

        try:
            await msg.edit_text(ai_text)
        except:
            await app.send_message(message.from_user.id, ai_text, parse_mode=enums.ParseMode.MARKDOWN)

@func(filters.command('style', prefixes=['.', '!', '/']))
async def change_style(app: Client, message: types.Message):
    global config
    if len(message.text.split()) == 1:
        config['style'] = '–æ–±—ã—á–Ω—ã–π'

        return await message.edit_text('–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –∏–∑–º–µ–Ω—ë–Ω –Ω–∞ `–æ–±—ã—á–Ω—ã–π`.', parse_mode=enums.ParseMode.MARKDOWN)
    
    style = ' '.join(message.text.split()[1:])

    print(config['style'])

    config['style'] = style

    await message.edit_text(f'–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –∏–∑–º–µ–Ω—ë–Ω –Ω–∞: `{style}`', parse_mode=enums.ParseMode.MARKDOWN)